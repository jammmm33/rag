{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b25c76",
   "metadata": {},
   "source": [
    "# [ë¬¸ì œ]\n",
    "- law_2.docx íŒŒì¼ì„ ì½ê³ , Chroma ì €ì¥\n",
    "- LLM ì§ˆë¬¸ -> ë‹µë³€\n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ì— ê´€í•œ ë²•ë¥  ì§ˆë¬¸ë§Œ ë°›ê¸°\n",
    "- ì´ ì™¸ì˜ ì§ˆë¬¸ì€ 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e96f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "## 1. ë¬¸ì„œ ë‚´ìš© ì½ê³  ë¶„í• \n",
    "loader = Docx2txtLoader('law_2.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex= False,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "## 2. ì„ë² ë”© -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "## 2.1 í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "## 2.2 ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model = 'text-embedding-3-large')\n",
    "\n",
    "## 2.3 ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "## [ë°©ë²• 1] in memory\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec70b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## [ë°©ë²• 2] Pinecone server\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "database = PineconeVectorStore.from_documents(\n",
    "    embedding=embedding,\n",
    "    index_name = 'law-3-index',\n",
    "    documents= document_list,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673a69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì„¸ì‚¬ê¸° í”¼í•´ìì˜ ì„ëŒ€ì¸ì— ëŒ€í•œ êµ­ì„¸ì˜ ê³„ì‚°ì€ ì‹œí–‰ë ¹ ì œ3ì¡°ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì„ëŒ€ì¸ì˜ êµ­ì„¸ëŠ” ìƒì†ì„¸, ì¦ì—¬ì„¸, ì¢…í•©ë¶€ë™ì‚°ì„¸ì¼ ê²½ìš° ê°ê°ì˜ ê³ ì§€ ë˜ëŠ” ì‹ ê³  ê±´ë³„ë¡œ ê³„ì‚°ëœ ê¸ˆì•¡ ì¤‘ ë” í° ê¸ˆì•¡ìœ¼ë¡œ ì‚°ì •ë©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ê³„ì‚°ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ìƒì†ì„¸, ì¦ì—¬ì„¸ ë° ì¢…í•©ë¶€ë™ì‚°ì„¸ì˜ ê²½ìš°: \n",
      "   - ê³ ì§€ ë˜ëŠ” ì‹ ê³  ê±´ë³„ë¡œ ê°ê° ê°€ëª©ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡ê³¼ \n",
      "   - ì„ëŒ€ì¸ì´ ì²´ë‚©í•œ ê³ ì§€ ë˜ëŠ” ì‹ ê³  ê±´ë³„ êµ­ì„¸ ê¸ˆì•¡ ì¤‘ ê³¼ì„¸ ëŒ€ìƒ ì¬ì‚°ì— ë¶€ê³¼ëœ êµ­ì„¸ ê¸ˆì•¡ ì¤‘ í° ê¸ˆì•¡ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. ìƒì†ì„¸, ì¦ì—¬ì„¸ ë° ì¢…í•©ë¶€ë™ì‚°ì„¸ ì™¸ì˜ êµ­ì„¸ì˜ ê²½ìš°: \n",
      "   - ê° ê³ ì§€ ë˜ëŠ” ì‹ ê³  ê±´ë³„ë¡œ ê°€ëª©ì— ë”°ë¼ ê³„ì‚°í•œ ê¸ˆì•¡ìœ¼ë¡œ ì‚°ì •ë©ë‹ˆë‹¤.\n",
      "\n",
      "ê³„ì‚°ì‹ì—ì„œ \"ì „ì„¸ì‚¬ê¸° í”¼í•´ì£¼íƒì˜ ì„ëŒ€ì¸ì´ ë³´ìœ í•œ ëª¨ë“  ì£¼íƒì˜ ê°€ê²© í•©ê³„ì•¡\"ì€ ì„ëŒ€ì¸ì˜ ëª¨ë“  ì£¼íƒì˜ ì‹œê°€í‘œì¤€ì•¡ì„ í•©ì‚°í•œ ê¸ˆì•¡ìœ¼ë¡œ í•˜ê³ , \"ì „ì„¸ì‚¬ê¸° í”¼í•´ì£¼íƒì˜ ê°€ê²©\"ì€ í•´ë‹¹ ê³¼ì„¸ê¸°ì¤€ì¼ì˜ ì‹œê°€í‘œì¤€ì•¡ìœ¼ë¡œ í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 3. ì§ˆë¬¸ -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(vector store)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "## 3.1 ì‚¬ìš©ì ì§ˆë¬¸\n",
    "query = 'ì „ì„¸ì‚¬ê¸° í”¼í•´ì ì„ëŒ€ì¸ì˜ êµ­ì„¸ê³„ì‚°ì€ ì–´ë–»ê²Œ ë¼?'\n",
    "# query = 'ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ ì •í•´ì¤˜~'\n",
    "\n",
    "## 3.2 ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "## 3.3 ë¬¸ì„œ ê°ì²´ -> í•˜ë‚˜ì˜ ë¬¸ìì—´\n",
    "context = 'ğŸ˜ğŸ˜\\n'.join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "## 4. ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ LLMì— ì§ˆë¬¸ê³¼ ê°™ì´ ì „ë‹¬\n",
    "## 4.1 í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "prompt = ''' \n",
    "[identity]\n",
    "ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ëŠ” ì „ì„¸ì‚¬ê¸° í”¼í•´ì ì§€ì›ì— ê´€í•œ ë²•ë ¹ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "\n",
    "- [context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ ë²•ë¥  ì´ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "question: {query}\n",
    "'''\n",
    "## 4.2 í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ê°’ ì„¤ì •\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs = context, \n",
    "    query=query)\n",
    "\n",
    "## 4.3  LLM ëª¨ë¸ ìƒì„±(hatOpenAIì¸ìŠ¤í„´ìŠ¤ ìƒì„±)\n",
    "llm = ChatOpenAI(model= 'gpt-4o')\n",
    "\n",
    "## 4.4 LLM ëª¨ë¸ì— ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œ ë³´ë‚´ê¸°\n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "print(ai_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
