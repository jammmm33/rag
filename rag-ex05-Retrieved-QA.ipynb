{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2800a99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\1\\miniconda3\\envs\\project\\lib\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c478e89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0404ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50ee4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "LANGCHAIN_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d51667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                         Type                              Data/Info\n",
      "----------------------------------------------------------------------------\n",
      "ChatOpenAI                       ModelMetaclass                    <class 'langchain_openai.<...>_models.base.ChatOpenAI'>\n",
      "FAISS                            ABCMeta                           <class 'langchain_communi<...>ectorstores.faiss.FAISS'>\n",
      "LANGCHAIN_API_KEY                str                               lsv2_pt_c235bcb425d144729<...>4d14df5abaf7a8_ab68fc6636\n",
      "OpenAIEmbeddings                 ModelMetaclass                    <class 'langchain_openai.<...>s.base.OpenAIEmbeddings'>\n",
      "RecursiveCharacterTextSplitter   ABCMeta                           <class 'langchain_text_sp<...>veCharacterTextSplitter'>\n",
      "RetrievalQA                      ModelMetaclass                    <class 'langchain.chains.<...>val_qa.base.RetrievalQA'>\n",
      "WebBaseLoader                    ABCMeta                           <class 'langchain_communi<...>.web_base.WebBaseLoader'>\n",
      "all_splits                       list                              n=133\n",
      "data                             list                              n=1\n",
      "hub                              module                            <module 'langchain.hub' f<...>ages\\\\langchain\\\\hub.py'>\n",
      "llm                              ChatOpenAI                        client=<openai.resources.<...>y=SecretStr('**********')\n",
      "load_dotenv                      function                          <function load_dotenv at 0x00000150287D71C0>\n",
      "loader                           WebBaseLoader                     <langchain_community.docu<...>ct at 0x0000015028805450>\n",
      "os                               module                            <module 'os' from 'c:\\\\Us<...>vs\\\\project\\\\lib\\\\os.py'>\n",
      "text_splitter                    RecursiveCharacterTextSplitter    <langchain_text_splitters<...>ct at 0x0000015034691450>\n",
      "vectorstore                      FAISS                             <langchain_community.vect<...>ct at 0x0000015037BEF490>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cc0a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_14780\\1693774383.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa_chain(\"What are autonomous agents?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are autonomous agents?',\n",
       " 'result': 'Autonomous agents are LLM-powered agents that can handle the autonomous design, planning, and performance of complex scientific experiments. These agents can browse the Internet, read documentation, execute code, call robotics experimentation APIs, and leverage other LLMs. They can develop novel solutions by reasoning through different steps and accessing external APIs for additional information.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm, ## llm 모델 설정 \n",
    "    retriever = vectorstore.as_retriever(), ## vector store 에서 문서 검색\n",
    "    prompt= prompt\n",
    ")\n",
    "\n",
    "qa_chain(\"What are autonomous agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf52b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autonomous agents are AI systems powered by LLMs that can handle complex scientific experiments by autonomously designing, planning, and performing tasks. These agents can browse the Internet, read documentation, execute code, call robotics experimentation APIs, and leverage other LLMs to gather missing information and improve their reasoning abilities. These agents can be used for various tasks, such as developing novel anticancer drugs, by utilizing external APIs for extra information and access to proprietary sources.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "            \"context\": vectorstore.as_retriever() | format_docs,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "\n",
    "qa_chain.invoke(\"What are autonomous agents?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
